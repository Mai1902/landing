{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mai1902/landing/blob/main/skills_cluster.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPvnSRsobVXL"
      },
      "outputs": [],
      "source": [
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install seaborn\n",
        "!pip install nltk\n",
        "!pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KrujTxFZaRnD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import re\n",
        "import nltk\n",
        "from sklearn import feature_extraction\n",
        "from nltk.stem import PorterStemmer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "qvY8G9_DipPi"
      },
      "outputs": [],
      "source": [
        "# Load job description file\n",
        "df = pd.read_csv('/dice_com-job_us_sample.csv')\n",
        "im_df = pd.DataFrame(df, columns = ['company', 'employment', 'jobdescription', 'jobtitle', 'skills'])\n",
        "data_dict = im_df.to_dict()\n",
        "jd_content = [x for x in data_dict['jobdescription'].values()]\n",
        "\n",
        "jd_content_sample = jd_content[:1000]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "E50i1sFseU6e"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bW_dT8bxddYx"
      },
      "outputs": [],
      "source": [
        "#initialize stop words and stemmer for text processing\n",
        "stopWords = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Epa-sCVWpaoi",
        "outputId": "1e40080f-68e8-4435-ce59-d5e9ee22cfdf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Y-AWoeGMfHkj"
      },
      "outputs": [],
      "source": [
        "'''Method to tokenize and stemmized the text'''\n",
        "def tokenize_and_stemmized(text):\n",
        "  tokens = []\n",
        "\n",
        "  #Add all tokenized word into list of token\n",
        "  for sent in nltk.sent_tokenize(text):\n",
        "    for word in nltk.word_tokenize(sent):\n",
        "      tokens.append(word)\n",
        "  filtered_tokens = []\n",
        "\n",
        "  # Filter out token that only contain letter, + sign,underscore, and number\n",
        "  for token in tokens:\n",
        "    if re.search(\"^[A-Za-z0-9+_-]*$\", token):\n",
        "      filtered_tokens.append(token)\n",
        "  stems = [stemmer.stem(t) for t in filtered_tokens]\n",
        "  return stems, filtered_tokens\n",
        "\n",
        "stemmed_and_filtered = []\n",
        "filtered_only = []\n",
        "for jd in jd_content:\n",
        "  stemmed_and_filtered = tokenize_and_stemmized(jd)[0]\n",
        "  filtered_only = tokenize_and_stemmized(jd)[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVRXGuZD3Sz7",
        "outputId": "363ed38e-2e02-47a3-bb70-f31c9760bea7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Experience', 'in', 'ProgrammingDevelopment', 'experience', 'in', 'Win32', 'Programming', 'on', 'Win', 'must', 'have', 'Experience', 'using', 'debuggers', 'such', 'as', 'WinDbgExperience', 'on', 'Windows', 'kernel']\n"
          ]
        }
      ],
      "source": [
        "print(filtered_only[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "HErpR1friNb-"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzAViE_Nn0yQ"
      },
      "outputs": [],
      "source": [
        "# define vectorizer parameters\n",
        "jd_forfit = [[jd for jd in jd_content_sample]]\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
        "                                 min_df=0.2, stop_words='english',\n",
        "                                 use_idf=True, tokenizer=tokenize_and_stemmized, ngram_range=(1,3))\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(jd_forfit)\n",
        "print(tfidf_matrix.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szaXjT350Mov",
        "outputId": "cf83e4a1-faa0-43f8-824a-8ff1a9f5d4b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "DC4AP9wqsl1U"
      },
      "outputs": [],
      "source": [
        "# Switch to LDA approach\n",
        "from gensim import corpora, models, similarities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyqKHWTg-oWB"
      },
      "outputs": [],
      "source": [
        "!pip install rake_nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "I22PBfmu-jg0"
      },
      "outputs": [],
      "source": [
        "from rake_nltk import Rake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "5JwX5fXg-ui4"
      },
      "outputs": [],
      "source": [
        "# Get keyword only from jd_content\n",
        "rake = Rake()\n",
        "for jd in jd_content_sample:\n",
        "  rake.extract_keywords_from_text(jd)\n",
        "keywords = rake.get_ranked_phrases()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "Vm0YCC1T0V29"
      },
      "outputs": [],
      "source": [
        "# remove stop words from list of tokenized and stemmed token\n",
        "filtered_only = [[word for word in tokenize_and_stemmized(keys)[1]] for keys in keywords]\n",
        "\n",
        "cleaned_jd = [[word for word in text if word not in stopWords] for text in filtered_only]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "Nc4mDiD4045Z"
      },
      "outputs": [],
      "source": [
        "# Create a Gensim dictionary from the processced job description\n",
        "dictionary = corpora.Dictionary(cleaned_jd)\n",
        "\n",
        "# Remove the extreme vocab based on term frequency\n",
        "dictionary.filter_extremes(no_below=1,no_above=0.8)\n",
        "\n",
        "#convert dictionary to a bag of words corpus\n",
        "corpus = [dictionary.doc2bow(jd) for jd in cleaned_jd]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WHg2riX3hw5",
        "outputId": "1063c903-0c48-4d6c-9037-4aa3fafc12f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dictionary(389 unique tokens: ['development', 'experience', 'initiatives', 'methodologies', 'modern']...)\n"
          ]
        }
      ],
      "source": [
        "print(dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n68yozf52aX5",
        "outputId": "57ca58e2-4a1d-4454-d8de-46627edb3e20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(18,\n",
              "  '0.077*\"understanding\" + 0.042*\"models\" + 0.042*\"use\" + 0.042*\"growing\" + 0.021*\"data\" + 0.021*\"business\" + 0.021*\"deep\" + 0.021*\"ideal\" + 0.021*\"day\" + 0.021*\"consists\"'),\n",
              " (6,\n",
              "  '0.038*\"solutions\" + 0.038*\"architecture\" + 0.038*\"etc\" + 0.038*\"cutting\" + 0.020*\"solution\" + 0.020*\"based\" + 0.020*\"best\" + 0.020*\"possible\" + 0.020*\"janeiro\" + 0.020*\"digital\"'),\n",
              " (13,\n",
              "  '0.151*\"experience\" + 0.076*\"team\" + 0.031*\"members\" + 0.016*\"extreme\" + 0.016*\"web\" + 0.016*\"aws\" + 0.016*\"restful\" + 0.016*\"home\" + 0.016*\"successful\" + 0.016*\"html5\"'),\n",
              " (19,\n",
              "  '0.108*\"development\" + 0.047*\"experience\" + 0.031*\"practical\" + 0.031*\"product\" + 0.031*\"realize\" + 0.016*\"various\" + 0.016*\"one\" + 0.016*\"across\" + 0.016*\"online\" + 0.016*\"less\"'),\n",
              " (5,\n",
              "  '0.060*\"boston\" + 0.060*\"deployment\" + 0.030*\"architecture\" + 0.030*\"models\" + 0.030*\"software\" + 0.030*\"leader\" + 0.030*\"backgrounds\" + 0.030*\"may\" + 0.030*\"wide\" + 0.030*\"www\"'),\n",
              " (0,\n",
              "  '0.051*\"sql\" + 0.051*\"integration\" + 0.051*\"continuous\" + 0.045*\"aware\" + 0.026*\"communication\" + 0.026*\"travel\" + 0.026*\"website\" + 0.026*\"ability\" + 0.026*\"com\" + 0.026*\"interpersonal\"'),\n",
              " (9,\n",
              "  '0.064*\"knowledge\" + 0.064*\"specifications\" + 0.043*\"skills\" + 0.043*\"technical\" + 0.043*\"grow\" + 0.022*\"oriented\" + 0.022*\"mobile\" + 0.022*\"5\" + 0.022*\"general\" + 0.022*\"important\"'),\n",
              " (15,\n",
              "  '0.043*\"years\" + 0.043*\"learning\" + 0.022*\"rackspace\" + 0.022*\"new\" + 0.022*\"techniques\" + 0.022*\"every\" + 0.022*\"solution\" + 0.022*\"subsequently\" + 0.022*\"nearly\" + 0.022*\"best\"'),\n",
              " (7,\n",
              "  '0.048*\"experience\" + 0.048*\"implementation\" + 0.048*\"functional\" + 0.025*\"team\" + 0.025*\"preferred\" + 0.025*\"6\" + 0.025*\"equivalent\" + 0.025*\"functions\" + 0.025*\"standards\" + 0.025*\"user\"'),\n",
              " (11,\n",
              "  '0.074*\"solution\" + 0.049*\"complex\" + 0.049*\"creativity\" + 0.049*\"involved\" + 0.025*\"building\" + 0.025*\"problems\" + 0.025*\"competitive\" + 0.025*\"salary\" + 0.025*\"diverse\" + 0.025*\"architect\"')]"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create LDA model with 20 different clusters\n",
        "lda = models.LdaModel(corpus, num_topics=20, \n",
        "                            id2word=dictionary, \n",
        "                            update_every=5, \n",
        "                            chunksize=10000, \n",
        "                            passes=100)\n",
        "lda.show_topics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FULSgZWw2s7d",
        "outputId": "594c6123-9344-4dd5-cd8d-8c18da1d1377"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['delivery', 'new', 'drive', 'constantly', 'monitoring', 'improve', 'right', 'programming', 'postgresql', 'languages', 'project', 'execution', 'enhance', 'yet', 'problems', 'exciting', 'difficult', 'process', 'teammates', 'combination']\n",
            "\n",
            "['knowledge', 'specifications', 'skills', 'technical', 'grow', 'get', 'object', 'opportunity', '5', 'general', 'oriented', 'programming', 'mobile', 'growth', 'information', 'important', 'ranging', 'user', 'infrastructure', 'setup']\n",
            "\n",
            "['collaborate', 'working', 'good', 'directly', 'split', 'responsibilitiesworking', 'context', 'bulletproof', 'number', 'love', 'wields', 'also', 'problem', 'solving', 'solution', 'data', 'architecture', 'creative', 'implementation', 'delivery']\n",
            "\n",
            "['work', 'project', 'edge', 'benefits', 'startups', 'available', 'using', 'specifics', 'responsibilities', 'following', 'inception', 'bonus', 'complete', 'including', 'package', 'chicago', 'health', 'delivered', 'choice', 'leverage']\n",
            "\n",
            "['test', 'phases', 'automation', 'revel', 'optimistic', 'clean', 'cloud', 'realistic', 'design', 'yet', 'fact', 'appreciation', 'exceeds', 'expectations', 'development', 'team', 'beginning', 'elite', 'set', 'integration']\n",
            "\n",
            "['requirements', 'class', 'writing', 'solutions', 'role', 'good', 'frameworks', 'experience', 'technical', 'attitude', 'beyond', 'ability', 'driving', 'entrepreneurs', 'individual', 'best', 'mentorship', 'includes', 'growth', 'powered']\n",
            "\n",
            "['solution', 'involved', 'complex', 'creativity', 'creating', 'problems', 'competitive', 'salary', 'diverse', 'building', 'teach', 'architect', 'appreciated', 'gaps', 'skills', 'squarely', 'non', 'director', 'project', 'roadblocks']\n",
            "\n",
            "['continuous', 'sql', 'integration', 'aware', 'website', 'travel', 'communication', 'net', 'interpersonal', 'com', 'skills', 'ability', 'principal', 'challenging', 'areas', 'engineerlocation', 'server', 'end', 'research', 'estimation']\n",
            "\n",
            "['development', 'experience', 'practical', 'product', 'realize', 'various', 'owners', 'management', 'relational', 'cycle', 'endless', 'experienced', 'less', 'one', 'multiple', 'apply', 'online', 'please', 'across', 'san']\n",
            "\n",
            "['challenge', 'quality', 'company', 'application', 'end', 'clear', 'based', 'ensure', 'delivery', 'assurance', 'simple', 'enjoyable', 'occasion', 'approaches', 'desktop', 'system', 'agile', 'solid', 'developing', 'product']\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "topics_matrix = lda.show_topics(formatted=False, num_words=20)\n",
        "topics_matrix = np.array(topics_matrix)\n",
        "\n",
        "topic_words = topics_matrix[:,1]\n",
        "for i in topic_words:\n",
        "    print([str(word[0]) for word in i])\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNzMWJ8kWIvNxOol8kND7On",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.1 64-bit ('3.9.1')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "f3988a7ffadf481798c71ca0893af6b07df2fdcf1ddebd12befc9d6c8efc13e0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
